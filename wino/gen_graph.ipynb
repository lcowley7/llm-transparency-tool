{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llmtt/lib/python3.12/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from llm_transparency_tool.models.tlens_model import TransformerLensTransparentLlm\n",
    "from llm_transparency_tool.models.transparent_llm import TransparentLlm\n",
    "import llm_transparency_tool.routes.graph as lmttg\n",
    "\n",
    "B0 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.amp import autocast\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import networkx as nx\n",
    "\n",
    "def cached_run_inference_and_populate_state(\n",
    "    stateless_model,\n",
    "    sentences,\n",
    "):\n",
    "    stateful_model = stateless_model.copy()\n",
    "    \n",
    "    stateful_model.run(sentences)\n",
    "    return stateful_model\n",
    "\n",
    "\n",
    "def get_contribution_graph(\n",
    "    model: TransparentLlm,\n",
    "    threshold: float,\n",
    ") -> nx.Graph:\n",
    "    \"\"\"\n",
    "    The `model_key` and `tokens` are used only for caching. The model itself is not\n",
    "    hashed, hence the `_` in the beginning.\n",
    "    \"\"\"    \n",
    "    return lmttg.build_full_graph(\n",
    "        model,\n",
    "        B0,\n",
    "        threshold,\n",
    "    )\n",
    "\n",
    "def get_contribution_graph_contrast(\n",
    "    base_model: TransparentLlm,\n",
    "    contrast_model: TransparentLlm,\n",
    "    threshold: float,    \n",
    ") -> nx.Graph:\n",
    "    \"\"\"Get the graph by using the contrast of the two models.\n",
    "    \n",
    "    Use object id for models, and added model_key and tokens for hashing purposes\n",
    "\n",
    "    Args:\n",
    "        base_model (TransparentLlm): Model 1, the one to be contrast\n",
    "        contrast_model (TransparentLlm): Model 2, the one to compare\n",
    "        threshold (float): Threshold to keep the edge.\n",
    "\n",
    "    Returns:\n",
    "        nx.Graph: Resulting graph.\n",
    "    \"\"\"    \n",
    "    return lmttg.build_full_graph_with_contrast(\n",
    "        base_model,\n",
    "        contrast_model,\n",
    "        B0,\n",
    "        threshold,\n",
    "    ) \n",
    "\n",
    "\n",
    "class GraphGen():\n",
    "    _stateful_model: TransparentLlm = None\n",
    "    _graph: Optional[nx.Graph] = None\n",
    "    _contribution_threshold: float = 0.0\n",
    "    _renormalize_after_threshold: bool = True\n",
    "    _normalize_before_unembedding: bool = True\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dtype = torch.float16\n",
    "        self.amp_enabled = self.dtype != torch.float32\n",
    "        \n",
    "    def set_sentence(self, sentence):\n",
    "        self.sentence = sentence\n",
    "        \n",
    "    def set_contribution_threshold(self, threshold: float):\n",
    "        self._contribution_threshold = threshold\n",
    "        \n",
    "    def load_model(self, model_name, revision = None):\n",
    "        self._stateful_model = TransformerLensTransparentLlm(\n",
    "            model_name=model_name,\n",
    "            device=\"gpu\",\n",
    "            dtype=torch.float16,\n",
    "            model_revision=revision,\n",
    "        )\n",
    "        \n",
    "        self.model_key = model_name\n",
    "\n",
    "    @property\n",
    "    def stateful_model(self) -> TransparentLlm:\n",
    "        return self._stateful_model\n",
    "\n",
    "\n",
    "    def build_graph(self):\n",
    "        threshold = self._contribution_threshold if not self._renormalize_after_threshold else 0.0\n",
    "                \n",
    "        tokens = self.stateful_model.tokens()[B0]\n",
    "        n_tokens = tokens.shape[0]\n",
    "        model_info = self.stateful_model.model_info()\n",
    "        \n",
    "        graphs = lmttg.build_paths_to_predictions(\n",
    "            self._graph,\n",
    "            model_info.n_layers,\n",
    "            n_tokens,\n",
    "            range(n_tokens),\n",
    "            threshold,\n",
    "        )\n",
    "        \n",
    "        token_strs = self.stateful_model.tokens_to_strings(tokens)\n",
    "        \n",
    "        edge_weights = {}\n",
    "        for u, v, weight in self._graph.edges(data=\"weight\"):\n",
    "            edge_weights[(u,v)] = weight\n",
    "        \n",
    "        return graphs, edge_weights\n",
    "\n",
    "        # return llm_transparency_tool.components.contribution_graph(\n",
    "        #     model_info,\n",
    "        #     self.stateful_model.tokens_to_strings(tokens),\n",
    "        #     graphs,\n",
    "        #     key=f\"graph_{hash(self.sentence)}\",\n",
    "        # )\n",
    "\n",
    "\n",
    "    def run_inference(self):    \n",
    "        # We added pair mode to contrast results of two sentences.\n",
    "        is_pair_mode = False\n",
    "        \n",
    "        with autocast(enabled=self.amp_enabled, device_type=\"cuda\", dtype=self.dtype):\n",
    "            if \" ||| \" in self.sentence:\n",
    "                # in pair mode\n",
    "                base_sent, contrast_sent = self.sentence.split(\" ||| \")\n",
    "\n",
    "                # set self._stateful_model to be the base model\n",
    "                self._stateful_model = cached_run_inference_and_populate_state(self.stateful_model, base_sent)\n",
    "                contrast_state = cached_run_inference_and_populate_state(self.stateful_model, contrast_sent)                \n",
    "                is_pair_mode = True\n",
    "                \n",
    "                n_tokens_base = self._stateful_model.tokens()[B0].shape[0]                \n",
    "                n_tokens_contrast = contrast_state.tokens()[B0].shape[0]\n",
    "                \n",
    "                assert n_tokens_base == n_tokens_contrast                \n",
    "            else:\n",
    "                self._stateful_model = cached_run_inference_and_populate_state(self.stateful_model, [self.sentence])\n",
    "\n",
    "\n",
    "        if is_pair_mode:\n",
    "            with autocast(enabled=self.amp_enabled, device_type=\"cuda\", dtype=self.dtype):\n",
    "                # set the app graph to use base state first\n",
    "                self._graph = get_contribution_graph_contrast(\n",
    "                    self._stateful_model,\n",
    "                    contrast_state,\n",
    "                    (self._contribution_threshold if self._renormalize_after_threshold else 0.0),\n",
    "                )\n",
    "        else:\n",
    "            with autocast(enabled=self.amp_enabled, device_type=\"cuda\", dtype=self.dtype):\n",
    "                self._graph = get_contribution_graph(\n",
    "                    self.stateful_model,\n",
    "                    (self._contribution_threshold if self._renormalize_after_threshold else 0.0),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 07:58:34.751 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/conda/envs/llmtt/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on revision  ckpt_008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e9d5d7856742e3a3b75e5ce89adf4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5c0a92991a481d88b4e7ef2ccbde1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_017\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c983d5ab87d04ceb829ea7d6dba0fcc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeebac39e3f4460db6ea55132543dd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_026\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b4a335d5854d1eb7befcce740cb5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e972a686f391486c946313f9250b48e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb75275ffe854fd7951678da47379839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a110a7734840fc899fc587f51dac9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_044\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef67b47a770c4d838b4ba860be5faf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3f33f448034740961185b76f3646af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_053\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb94fb86ca9f4cffaf3f61a976d7fec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88767b58a4144051b8980fb0138ce4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6ba5c0dba042f5a49e0530d5baaa52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bddb25ebe749299ab77932f14e5dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_071\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdeb46485724d8dab759dc3b94e3eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498c38667126477289fc089c7debd950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_080\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1678f4effc2c4c47b6df6e7b6d55fd93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f320e3d06ce43e28109e681c48ea00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ad838d5b934523a7152a46847331d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4685bc8c1b4d3b82fb27e7e4cb0f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_098\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1301e2180be4e6489e9285ecd445a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e2d495f47b4789856923c3e56d8381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63c5a1cfcf14bf9bb0f0a359f3248fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e74235cc6984209b6b5e3392417a8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3848def20e74ff7a916a1f6b83a17bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09355acdb0874e2aac85fc0dff81bb66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469e6a70720544b3b9d606d088a1a3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4696fc3dfd431c8cebf8d339556256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67633eb9e4e4e35996c147ae6aa36bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edaae284c4694c77a2eb3f56a5ac3992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c848a80e684039aefc66886458c648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c589c36c1d8456e9a4efaf0ebd169f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b6da1d1bd746809707a2c2f6af343b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe40c62eb824e189d918e857fb9c066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270a23826ddf44dd9e576058593a8079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6643f3afef941d9b1b46aea3df44b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8f1dde0ad84d499cb63b87d3b4bc5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbfd9a7195c4023b200c8914a3e459b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_179\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b474c712cd3447c0b60308354364dfe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f898449e5647ec85ee03a77c6023d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4f7640c7b44adca866b1d813691995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67c7994f33a496abb94bdf6709356ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34dc4ef6aef04f3489d553d9659d6d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c6644d1a1241ea9fb4f4c54480e60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fba14922864a90a7523960b5da714a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e214cdbd8db24289896e4076d853a1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99548a10031548e8a0e3397c59b720bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30eece7ebfef4d6cb3ac50cd33a92aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb6d23d4bfd45cf9b279ec87de178b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08e9fcbbe114dc987d44a0c652c8b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15755d58779a4f24a965e3f63dfd1070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa5b4ce88684f32ac6f67612ff272ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d509d1257fa14571b542afad959a567a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737fd41fe3af4e4c86d780fc273c0816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfada373a2442b2924cfc6bd213abcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41062357140644419c983802feba6ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414e251a936047aeaaddf9df763b3536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83a73877c0f4201821b08db5cd96f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567bfb554ecb4826b9d80de3fae62522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bae814f2e274671be850bbd4e2ae7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_278\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5491dddf9cc4b26823ecdb4c6d1d055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bff803f1dbe4effa09b3e44f185ebc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_287\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5976df15bbaa4c9cbdcea3820e42fd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6775d0518a146ab8a8fa4385f41a56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0c926ce87e4e3e9f6470775dd44c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2791d7fa084b02816e4c08b5ef5988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b98d1298874b7187c55fd6d1c966d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b4a4de741841db9423c2413f50d7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_314\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c1786c913742f0bf1ae3833e94e125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4e9fe45c4541f69cf57740ec566e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_323\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e270601ea45246528b1710cdd28d5ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55130e0d88504e638895244a8b7ff72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_332\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64156acb7ab5401aa4b5ecc276b8803b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b095d91db04ca9bd5c107f1b337ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595f39bd36e14753b2c2b38ba3160b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe1d9ac959540ac9ec30f6c851298d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  ckpt_350\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca2ddeaa6234570a2bdf95b9c703353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28800f93db034e85bc6a69fcf2782436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n",
      "Working on revision  main\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6cbb55ae634ab69d5eae37ec30cf99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de17f8785b54aafb8de80441f2c199d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model LLM360/Amber into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "revisions = [f\"ckpt_{n:03d}\" for n in range(8, 351, 9)]\n",
    "# revisions = [f\"ckpt_{n:03d}\" for n in range(8, 36, 9)]\n",
    "revisions.append(\"main\")\n",
    "\n",
    "sents = [\n",
    "    \"Sarah was a much better surgeon than Maria, so the harder cases always went to\",\n",
    "    \"Sarah was a much better surgeon than Maria, so the easier cases always went to\",\n",
    "    \"Keeping the doors closed and the windows opened kept the apartment cool , because the heat was let out by the\",\n",
    "    \"Keeping the doors closed and the windows opened kept the apartment cool , because the heat was kept out by the\",\n",
    "    \"In the hotel laundry room, Emma burned Mary's shirt while ironing it, so the manager scolded\",\n",
    "    \"In the hotel laundry room, Emma burned Mary's shirt while ironing it, so the manager refunded\",\n",
    "    \"They had to eat a lot to gain the strength they had lost and be able to work, they had too much\",\n",
    "    \"They had to eat a lot to gain the strength they had lost and be able to work, they had too little\",\n",
    "]\n",
    "\n",
    "\n",
    "graph_timeline = {}\n",
    "\n",
    "for rev in revisions:\n",
    "    print(\"Working on revision \", rev)\n",
    "    gg = GraphGen()\n",
    "    gg.load_model(\"LLM360/Amber\", rev)\n",
    "    graph_timeline[rev] = []\n",
    "    for s in sents:\n",
    "        gg.set_sentence(s)\n",
    "        gg.set_contribution_threshold(0.02)\n",
    "        gg.run_inference()\n",
    "        graphs, edge_weights = gg.build_graph()\n",
    "        \n",
    "        graph_timeline[rev].append((graphs, edge_weights))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def jaccard_similarity(edges1, edges2):\n",
    "    \"\"\"\n",
    "    Compute the Jaccard similarity between two sets of edges.\n",
    "\n",
    "    Args:\n",
    "    edges1 (list of tuples): First list of edges.\n",
    "    edges2 (list of tuples): Second list of edges.\n",
    "\n",
    "    Returns:\n",
    "    float: Jaccard similarity between edges1 and edges2.\n",
    "    \"\"\"\n",
    "    set1 = set(edges1)\n",
    "    set2 = set(edges2)\n",
    "    \n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    \n",
    "    if not union:\n",
    "        return 0.0\n",
    "    \n",
    "    # print(\n",
    "    #     f\"set 1 has {len(set1)} edges, set 2 has {len(set2)} edges, intersection is {len(intersection)}, union is {len(union)}\")\n",
    "    return len(intersection) / len(union)\n",
    " \n",
    "def weighted_jaccard_similarity(edges1, weights1, edges2, weights2):\n",
    "    \"\"\"\n",
    "    Compute the weighted Jaccard similarity between two sets of edges with weights.\n",
    "\n",
    "    Args:\n",
    "    edges1 (list of tuples): First list of edges.\n",
    "    weights1 (dict): Dictionary of weights for edges in the first list.\n",
    "    edges2 (list of tuples): Second list of edges.\n",
    "    weights2 (dict): Dictionary of weights for edges in the second list.\n",
    "\n",
    "    Returns:\n",
    "    float: Weighted Jaccard similarity between edges1 and edges2.\n",
    "    \"\"\"\n",
    "    set1 = set(edges1)\n",
    "    set2 = set(edges2)\n",
    "    \n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    \n",
    "    if not union:\n",
    "        return 0.0\n",
    "    \n",
    "    intersection_sum = sum(min(weights1[e], weights2[e]) for e in intersection)\n",
    "    union_sum = sum(max(weights1.get(e, 0), weights2.get(e, 0)) for e in union)\n",
    "    \n",
    "    return intersection_sum / union_sum\n",
    " \n",
    "def write_jaccard_similarities_to_csv(sents, revisions, graph_timeline, output_file):\n",
    "    final_graphs = graph_timeline['main']\n",
    "    \n",
    "    with open(output_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Sentence', 'Revision', 'Jaccard', 'Weighted Jaccard'])\n",
    "        \n",
    "        for i, sent in enumerate(sents):\n",
    "            for rev in revisions[:-1]:\n",
    "                g1, g1w = graph_timeline[rev][i]\n",
    "                g2, g2w = final_graphs[i]\n",
    "                \n",
    "                assert len(g1) == len(g2)\n",
    "                \n",
    "                g1edges = g1[-1].edges()            \n",
    "                g2edges = g2[-1].edges()\n",
    "                \n",
    "                jaccard = jaccard_similarity(g1edges, g2edges)\n",
    "                wj = weighted_jaccard_similarity(g1edges, g1w, g2edges, g2w)\n",
    "                \n",
    "                writer.writerow([sent, rev, jaccard, wj])\n",
    "\n",
    "output_file = 'jaccard_similarities.csv'\n",
    "write_jaccard_similarities_to_csv(sents, revisions, graph_timeline, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
